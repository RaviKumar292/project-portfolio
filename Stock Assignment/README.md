**Financial News Multi-Agent System — README**

---

**Project Overview**

This project builds an intelligent **Financial News Assistant** that can answer user questions like:

* *“Why did RBI penalize HDFC Bank?”*
* *“What happened to ICICI Bank this week?”*
* *“Show me the latest regulatory news.”*

The system processes thousands of news articles using a **multi-agent pipeline** and enables:

* Automated news cleaning and preprocessing
* Semantic deduplication of articles
* Entity extraction (companies, regulators, sectors, dates)
* Stock-impact tagging
* Vector storage in **ChromaDB**
* High-accuracy retrieval
* JSON-safe answers generated by **Gemini 2.5 Flash-Lite**
* Fallback rule-based reasoning when LLM fails

This notebook demonstrates a complete **end-to-end GenAI + Retrieval** workflow designed for financial analysis.

---

**Technology Stack**

**Data & Storage**

* Python (JSON processing)
* ChromaDB Vector Store
* Sentence-Transformers (`all-MiniLM-L6-v2`)
* JSON-based datasets
* Local persistent embeddings storage

** LLM & AI Components**

* Google Gemini 2.5 Flash-Lite
* Multi-Agent Architecture

  * Ingestion Agent
  * Deduplication Agent
  * Entity Extraction Agent
  * Impact Agent
  * Storage Agent
  * Query Agent
* RAG (Retrieval Augmented Generation)
* LangGraph-style execution flow (manual + graph)

---

## **Setup Instructions**

### **Install Dependencies**

```bash
pip install pandas chromadb sentence-transformers
pip install google-generativeai
pip install langchain langgraph
```

### **Configure Gemini API**

```python
import google.generativeai as genai
genai.configure(api_key="YOUR_API_KEY")
```

---

## **How to Run the Pipeline**

### **Run Multi-Agent News Processing**

This creates cleaned data → deduped stories → entity tags → impact signals → stored in ChromaDB.

```python
python news_pipeline.py
```

### **Run a Query**

Ask any financial question:

```python
from query_pipeline import ask_financial_agent

ask_financial_agent("Why did RBI penalize HDFC Bank?")
```

### **You will receive structured JSON:**

* Final Answer
* Evidence Story IDs
* Confidence Score
* Retrieved Supporting News

---

## **What This Project Includes**

**Input Datasets**

* `rrs_news.json` — Raw scraped news
* `ddg_fetcher` output — Live fetched DuckDuckGo news
* Press releases CSV (HDFC regulatory announcements)

### **Generated Datasets**

* `all_news_cleaned.json` — Cleaned + normalized
* `all_news_deduped.json` — Unique stories
* `all_news_entities.json` — Extracted company/regulator entities
* `all_news_impact.json` — Stock impact tagging
* `vectorstore/` — ChromaDB embeddings store

---

**Key Notebook Functions**

### **Query Functions**

```python
run_news_pipeline()                # Runs full multi-agent pipeline
ask_financial_agent("...")         # Retrieves + generates final answer
```

**Internal Agents**

* `IngestionAgent` → Loads and cleans raw news
* `DedupeAgent` → Clusters similar stories
* `EntityAgent` → spaCy + LLM extraction
* `ImpactAgent` → Rule-based stock signal generation
* `StorageAgent` → Serialize to ChromaDB
* `QueryAgent` → LLM reasoning with strict JSON output

---

**Limitations**

* No UI (Notebook-only demo)
* Google Gemini free-tier limits reasoning depth
* ChromaDB stored locally
* Long news articles are truncated to avoid LLM overflow
* Entity extraction not 100% perfect on long or noisy articles

---

**Deliverables Shared**

* `Multi-Agent.ipynb` (Full implementation)
* Cleaned dataset + Press releases
* Output screenshots (PDF/manual)
* GitHub repository link with all code

---

